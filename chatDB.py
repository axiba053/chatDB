# !/usr/bin/env python
# -*-coding:utf-8 -*-
"""
# å…¬ä¼—å·/è§†é¢‘å·/Bç«™ ï¼šä¸‰å¼ºçš„å°å±‹
# Descriptionï¼šæ ¹æ®æé—®æŸ¥è¯¢æ•°æ®åº“ï¼Œå°†æŸ¥è¯¢ç»“æœè¾“å…¥chatgptè¾“å‡ºç­”æ¡ˆ
"""
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Qdrant
from langchain.chains import RetrievalQA
from langchain import OpenAI
from qdrant_client import QdrantClient
from dotenv import load_dotenv
import streamlit as st
from PIL import Image
import os
from createDB import CreateDB
import pathlib

def pre_brief():
    # æ ‡é¢˜ å›¾æ ‡
    image = Image.open('./image/AIgirl.png')
    st.set_page_config(page_title='å®¢æœ', layout='wide', page_icon=image)
    st.header('å’¨è¯¢å®¢æœğŸ’')
    #å·¦è¾¹æ 
    with st.sidebar:
        st.image(image, caption="", width=50)
        # st.markdown("---")
        st.markdown("## å®¢æœä½¿ç”¨è¯´æ˜")
        st.markdown("1. ä¸Šä¼ èµ„æ–™æ–‡ä»¶ï¼Œåˆ›å»º/æ›´æ–°æ•°æ®åº“")
        st.markdown("2. é€‰æ‹©æ•°æ®åº“æé—®")
        st.markdown("---")
        st.markdown("## ä½œè€…ç®€ä»‹")
        st.markdown("å¤§å®¶å¥½ï¼Œè¿™é‡Œæ˜¯:blue[ã€Šä¸‰å¼ºçš„å°å±‹ã€‹]ï¼")
        st.markdown("æ¬¢è¿åœ¨:green[Bç«™]æˆ–è€…:green[å¾®ä¿¡è§†é¢‘å·]å…³æ³¨ï¼Œäº†è§£æ›´å¤šç²¾å½©å†…å®¹!")
        image = Image.open("./image/B.jpg")
        st.image(image, caption="", width=250)

def suf_brief():
    st.markdown("---")
    st.write("æ‚¨å¥½,æ¬¢è¿å…³æ³¨æˆ‘çš„**Bç«™è´¦å·ã€å¾®ä¿¡è§†é¢‘å·åŠå…¬ä¼—å·**ğŸ‘")
    st.write("ä½œä¸ºçŸ¥è¯†çš„æ¬è¿å·¥ï¼Œæˆ‘ä¼šæŒç»­æ›´æ–°AIç›¸å…³æŠ€æœ¯åŠä½¿ç”¨ğŸ§")
    st.write("æœªæ¥AIä¼šåƒç”µè„‘ä¸€æ ·æ™®åŠï¼Œæ—©ç”¨æ™šç”¨ä¸å¦‚ç°åœ¨å°±ç”¨ï¼è®©æˆ‘ä»¬ä¸€èµ·æ¢ç´¢AIçš„é­…åŠ›å§ğŸ¤”")
    st.write("ï¸éå¸¸æ„Ÿè°¢æ‚¨çš„å…³æ³¨ä¸æ”¯æŒï¼ğŸ™")
    st.write("")
    # å›¾ç‰‡å±•ç¤º
    image1 = Image.open("./image/shipinhao.jpg")
    image2 = Image.open("./image/dingyuehao.jpg")
    image3 = Image.open("./image/wexin2.jpg")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.image(image1, caption="å¾®ä¿¡è§†é¢‘å·", width=200)
    with col2:
        st.image(image2, caption="å¾®ä¿¡è®¢é˜…å·", width=200)
    with col3:
        st.image(image3, caption="å¾®ä¿¡äº¤æµ", width=200)

def get_chain(DbName):
    embeddings = OpenAIEmbeddings()
    client = QdrantClient(path="./db", prefer_grpc=True)
    vector_store = Qdrant(
        client=client,
        collection_name=DbName,
        embeddings=embeddings
    )
    chain = RetrievalQA.from_chain_type(
        llm=OpenAI(temperature=0),
        chain_type="stuff",
        retriever=vector_store.as_retriever()
    )
    return chain

def ui():
    t1, t2 = st.tabs(['åˆ›å»ºæ•°æ®åº“', 'é€‰æ‹©æ•°æ®åº“æé—®'])
    with t1:
        File=st.file_uploader('ä¸Šä¼ pdf/docx/txt/csv/mdæ–‡ä»¶',
                              type=['pdf','docx','txt','csv','md'],
                         )
        if File:
            newFile = './tmp/' + File.name
            with open(pathlib.Path(newFile), 'wb') as f:
                f.write(File.read())
        dbName = st.text_input('è¾“å…¥æ–°å»º/æ›´æ–°æ•°æ®åº“åç§°',disabled= not File)
        sub = st.button('æäº¤',disabled= not (File and dbName))
        if sub:
            db = CreateDB(dbName, newFile)
            db.store_qdrand()
    with t2:
        #è¯»å–æ•°æ®åº“åç§°åˆ—è¡¨
        dbFiles=os.listdir('./db/collection')
        dbNames = tuple([name for name in dbFiles if not name.startswith('.')])
        DbName=st.selectbox('é€‰æ‹©æ•°æ®åº“ï¼š',dbNames)
        chain = get_chain(DbName)
        question = st.text_input('æé—®ï¼š',disabled= not DbName)
        if question:
            st.write(f'é—®ï¼š{question}')
            answer = chain.run(question)
            st.write(f'ç­”ï¼š{answer}')
    st.write("")

def main():
    load_dotenv()
    pre_brief()
    ui()
    suf_brief()

if __name__ == '__main__':
    main()

